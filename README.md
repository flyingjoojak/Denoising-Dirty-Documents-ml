# Denoising Dirty Documents

## 1. 프로젝트 개요
본 프로젝트는 Kaggle에서 진행된 “Denoising Dirty Documents” 대회를 기반으로  
**오염된 문서 이미지를 깨끗한 문서로 복원하는 이미지 복원(Denoising) 문제**를 다루었습니다.

오염은 커피 자국, 물 얼룩, 구겨짐 등으로 인위적으로 생성되었으며,  
문서 복원은 후속 OCR(Optical Character Recognition) 또는 문서 분석 작업의 성능을 크게 향상시킬 수 있는 중요한 과제입니다.

---

## 2. 데이터 설명
### 데이터셋 구성
- [데이터 출처](https://www.kaggle.com/competitions/denoising-dirty-documents/data)
- `train/`: 노이즈가 포함된 입력 이미지  
- `train_cleaned/`: 대응되는 깨끗한 이미지(정답 레이블)  
- `test/`: 평가용 노이즈 이미지  
- (선택적) `test_cleaned/`: 평가용 정답 (공개된 경우)

이미지 파일은 흑백 또는 컬러로 구성될 수 있으며,  
각 이미지 쌍(train, train_cleaned)은 노이즈 제거 학습용으로 제공됩니다.

---

## 3. 데이터 전처리 및 탐색
### 3.1 시각화 및 분포 파악
- 노이즈 패턴(예: 얼룩, 선, 배경 노이즈)을 시각적으로 확인했습니다.
- 이미지별 크기 및 색상 채널 분포를 조사했습니다.

### 3.2 전처리
- 이미지 정규화 및 스케일링 적용
- 필요 시 리사이징 또는 패딩 처리
- 학습 이미지와 정답 이미지 쌍으로 Dataset/Dataloader 구성

---

## 4. 모델링 접근
본 프로젝트에서는 **이미지 복원 모델**을 활용하여 노이즈 제거를 수행했습니다.

### 사용한 모델
- **Autoencoder** 기반 모델
  - Encoder와 Decoder 구조를 활용하여 노이즈 제거를 시도했습니다.
- **U-Net 스타일 구조** (옵션)
  - 컨볼루션을 통한 피쳐 추출 및 업샘플링 구조 사용

---

## 5. 학습 및 평가 방법
### 평가 지표
- RMSE(Root Mean Squared Error): 클린 이미지와 예측 이미지 간 픽셀 차이를 기준으로 평가합니다.

### 학습 설정
- 학습/검증 분할 비율 설정
- Batch size, Epoch, Optimizer 등 하이퍼파라미터 설정

---

## 6. 실험 결과
실험 과정에서 다음과 같은 관찰이 있었습니다:

- 단순 이미지 처리 기반(noise filtering) 접근은 제한적인 성능
- Autoencoder 기반 모델이 전체적인 노이즈 제거 성능 향상에 기여
- 모델 구조 변경 또는 데이터 augmentation이 추가 성능 개선에 도움

---

## 7. 한계점
- 데이터 사이즈가 비교적 작아 모델 학습이 제한적이었음
- 다양한 형태의 노이즈를 모두 일반화하기 어려움
- GPU/메모리 제약으로 복잡한 모델 실험이 제한됨

---

## 8. 향후 개선 방향
- 더 복잡한 네트워크(U-Net, GAN) 적용
- 데이터 확장 및 augmentation 기법 다양화
- Patch-based 학습을 통해 메모리 문제 완화

---

## 9. 프로젝트 의의
본 프로젝트는 **이미지 복원/전처리 관점에서 실제 문서 처리 문제를 탐색**한 사례입니다.  
문서 클렌징 모델은 OCR 등 후속 태스크 성능 향상에 직결되며,  
실제 산업용 문서 자동화 도구 제작에 응용될 수 있는 가능성을 확인했습니다.
